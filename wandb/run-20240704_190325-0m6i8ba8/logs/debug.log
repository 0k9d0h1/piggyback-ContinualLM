2024-07-04 19:03:25,840 INFO    MainThread:2595938 [wandb_setup.py:_flush():76] Current SDK version is 0.17.0
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_setup.py:_flush():76] Configure stats pid to 2595938
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_setup.py:_flush():76] Loading settings from /home/0k9d0h1/.config/wandb/settings
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_setup.py:_flush():76] Loading settings from /home/0k9d0h1/piggyback/piggyback-ContinualLM/wandb/settings
2024-07-04 19:03:25,841 WARNING MainThread:2595938 [wandb_setup.py:_flush():76] Unknown environment variable: WANDB_SERVICE
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': '0k9d0h1team', 'project': 'piggyback_continualDAP_sweep', 'sweep_id': '04z2g4d7', 'root_dir': '/home/0k9d0h1/piggyback/piggyback-ContinualLM', 'run_id': '0m6i8ba8', 'sweep_param_path': '/home/0k9d0h1/piggyback/piggyback-ContinualLM/wandb/sweep-04z2g4d7/config-0m6i8ba8.yaml'}
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'finetune.py', 'program_abspath': '/home/0k9d0h1/piggyback/piggyback-ContinualLM/finetune.py', 'program': 'finetune.py'}
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_init.py:_log_setup():520] Logging user logs to /home/0k9d0h1/piggyback/piggyback-ContinualLM/wandb/run-20240704_190325-0m6i8ba8/logs/debug.log
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_init.py:_log_setup():521] Logging internal logs to /home/0k9d0h1/piggyback/piggyback-ContinualLM/wandb/run-20240704_190325-0m6i8ba8/logs/debug-internal.log
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_init.py:init():560] calling init triggers
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_init.py:init():568] wandb.init called with sweep_config: {'baseline': 'lora_init', 'epoch': 17, 'finetune_type': 'lora_piggyback', 'ft_task': 0, 'hyperparameter_tune': True, 'idrandom': 0, 'lr': 7.343082687700502e-05, 'max_samples': 640000, 'max_seq_length': 164, 'ntasks': 1, 'pt_task': 0, 'seed': 1, 'weight_decay': 0.0010056043660498994}
config: {'seed': 1, 'dataset_name': 'restaurant_sup', 'model_name_or_path': './/seq0/640000samples/lora_init/restaurant_unsup_roberta/', 'output_dir': './/seq0/640000samples/lora_init/restaurant_unsup_roberta/', 'lr': 7.343082687700502e-05, 'batch_size': 16, 'params': None, 'epoch': 30, 'least_epoch': None, 'patient': 3, 'weight_decay': 0.0010056043660498994, 'tensorboard_dir': None, 'class_num': None, 'log_dir': None, 'precision': torch.float32, 'problem_type': 'single_label_classification', 'round': None, 'baseline': 'lora_init', 'saved_model': None, 'saved_output_dir': './ckpt', 'finetune_type': 'lora_piggyback', 'max_seq_length': 164, 'generator': '', 'train_sample_ratio': None, 'n_tokens': 100, 'num_warmup_steps': 0, 'lr_scheduler_type': 'linear', 'gradient_accumulation_steps': 1, 'max_train_steps': None, 'how_to_block': None, 'addition_loss': '', 'mlm_probability': 0.15, 'idrandom': 0, 'pt_task': 0, 'ft_task': 0, 'ntasks': 1, 'max_samples': 640000, 'base_dir': './', 'no_cuda': False, 's': 400, 'smax': 400, 'beta': 0.03, 'gamma': 0.75, 'alpha': 0.01, 'semantic_cap_size': 3, 'num_semantic_cap': 3, 'pipline_norm': 'standard_norm', 'hyperparameter_tune': True, 'eval_only': False, 'sequence_file': 'posttrain', 'reduction_factor': 16, 'lora_r': 8, 'lora_alpha': 16, 'base_model_name_or_path': 'roberta-base', 'task': 0, 'device': device(type='cuda')}
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_init.py:init():610] starting backend
2024-07-04 19:03:25,841 INFO    MainThread:2595938 [wandb_init.py:init():614] setting up manager
2024-07-04 19:03:25,847 INFO    MainThread:2595938 [backend.py:_multiprocessing_setup():107] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-07-04 19:03:25,848 INFO    MainThread:2595938 [wandb_init.py:init():622] backend started and connected
2024-07-04 19:03:25,860 INFO    MainThread:2595938 [wandb_run.py:_config_callback():1376] config_cb None None {'baseline': 'lora_init', 'epoch': 17, 'finetune_type': 'lora_piggyback', 'ft_task': 0, 'hyperparameter_tune': True, 'idrandom': 0, 'lr': 7.343082687700502e-05, 'max_samples': 640000, 'max_seq_length': 164, 'ntasks': 1, 'pt_task': 0, 'seed': 1, 'weight_decay': 0.0010056043660498994}
2024-07-04 19:03:25,861 INFO    MainThread:2595938 [wandb_init.py:init():711] updated telemetry
2024-07-04 19:03:25,874 INFO    MainThread:2595938 [wandb_init.py:init():744] communicating run to backend with 90.0 second timeout
2024-07-04 19:03:26,350 INFO    MainThread:2595938 [wandb_run.py:_on_init():2396] communicating current version
2024-07-04 19:03:26,460 INFO    MainThread:2595938 [wandb_run.py:_on_init():2405] got version response upgrade_message: "wandb version 0.17.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-07-04 19:03:26,461 INFO    MainThread:2595938 [wandb_init.py:init():795] starting run threads in backend
2024-07-04 19:03:30,552 INFO    MainThread:2595938 [wandb_run.py:_console_start():2374] atexit reg
2024-07-04 19:03:30,552 INFO    MainThread:2595938 [wandb_run.py:_redirect():2229] redirect: wrap_raw
2024-07-04 19:03:30,552 INFO    MainThread:2595938 [wandb_run.py:_redirect():2294] Wrapping output streams.
2024-07-04 19:03:30,552 INFO    MainThread:2595938 [wandb_run.py:_redirect():2319] Redirects installed.
2024-07-04 19:03:30,555 INFO    MainThread:2595938 [wandb_init.py:init():838] run started, returning control to user process
