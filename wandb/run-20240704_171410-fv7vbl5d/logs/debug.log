2024-07-04 17:14:10,525 INFO    MainThread:1986504 [wandb_setup.py:_flush():76] Current SDK version is 0.17.0
2024-07-04 17:14:10,525 INFO    MainThread:1986504 [wandb_setup.py:_flush():76] Configure stats pid to 1986504
2024-07-04 17:14:10,525 INFO    MainThread:1986504 [wandb_setup.py:_flush():76] Loading settings from /home/0k9d0h1/.config/wandb/settings
2024-07-04 17:14:10,525 INFO    MainThread:1986504 [wandb_setup.py:_flush():76] Loading settings from /home/0k9d0h1/piggyback/piggyback-ContinualLM/wandb/settings
2024-07-04 17:14:10,525 INFO    MainThread:1986504 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-07-04 17:14:10,525 INFO    MainThread:1986504 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-07-04 17:14:10,525 INFO    MainThread:1986504 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'finetune.py', 'program_abspath': '/home/0k9d0h1/piggyback/piggyback-ContinualLM/finetune.py', 'program': 'finetune.py'}
2024-07-04 17:14:10,525 INFO    MainThread:1986504 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-07-04 17:14:10,526 INFO    MainThread:1986504 [wandb_init.py:_log_setup():520] Logging user logs to /home/0k9d0h1/piggyback/piggyback-ContinualLM/wandb/run-20240704_171410-fv7vbl5d/logs/debug.log
2024-07-04 17:14:10,526 INFO    MainThread:1986504 [wandb_init.py:_log_setup():521] Logging internal logs to /home/0k9d0h1/piggyback/piggyback-ContinualLM/wandb/run-20240704_171410-fv7vbl5d/logs/debug-internal.log
2024-07-04 17:14:10,526 INFO    MainThread:1986504 [wandb_init.py:init():560] calling init triggers
2024-07-04 17:14:10,526 INFO    MainThread:1986504 [wandb_init.py:init():568] wandb.init called with sweep_config: {}
config: {'seed': 111, 'dataset_name': 'scierc_sup', 'model_name_or_path': './/seq0/640000samples/lora_init/ai_unsup_roberta/', 'output_dir': './/seq0/640000samples/lora_init/ai_unsup_roberta/', 'lr': 3e-05, 'batch_size': 16, 'params': None, 'epoch': 30, 'least_epoch': None, 'patient': 3, 'weight_decay': 0.01, 'tensorboard_dir': None, 'class_num': None, 'log_dir': None, 'precision': torch.float32, 'problem_type': 'single_label_classification', 'round': None, 'baseline': 'lora_init', 'saved_model': None, 'saved_output_dir': './ckpt', 'finetune_type': 'lora_piggyback', 'max_seq_length': 164, 'generator': '', 'train_sample_ratio': None, 'n_tokens': 100, 'num_warmup_steps': 0, 'lr_scheduler_type': 'linear', 'gradient_accumulation_steps': 1, 'max_train_steps': None, 'how_to_block': None, 'addition_loss': '', 'mlm_probability': 0.15, 'idrandom': 0, 'pt_task': 2, 'ft_task': 2, 'ntasks': 6, 'max_samples': 640000, 'base_dir': './', 'no_cuda': False, 's': 400, 'smax': 400, 'beta': 0.03, 'gamma': 0.75, 'alpha': 0.01, 'semantic_cap_size': 3, 'num_semantic_cap': 3, 'pipline_norm': 'standard_norm', 'hyperparameter_tune': False, 'eval_only': False, 'sequence_file': 'posttrain', 'reduction_factor': 16, 'lora_r': 8, 'lora_alpha': 16, 'base_model_name_or_path': 'roberta-base', 'task': 2, 'device': device(type='cuda')}
2024-07-04 17:14:10,526 INFO    MainThread:1986504 [wandb_init.py:init():610] starting backend
2024-07-04 17:14:10,526 INFO    MainThread:1986504 [wandb_init.py:init():614] setting up manager
2024-07-04 17:14:10,527 INFO    MainThread:1986504 [backend.py:_multiprocessing_setup():107] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-07-04 17:14:10,529 INFO    MainThread:1986504 [wandb_init.py:init():622] backend started and connected
2024-07-04 17:14:10,533 INFO    MainThread:1986504 [wandb_init.py:init():711] updated telemetry
2024-07-04 17:14:10,550 INFO    MainThread:1986504 [wandb_init.py:init():744] communicating run to backend with 90.0 second timeout
2024-07-04 17:14:11,040 INFO    MainThread:1986504 [wandb_run.py:_on_init():2396] communicating current version
2024-07-04 17:14:11,128 INFO    MainThread:1986504 [wandb_run.py:_on_init():2405] got version response upgrade_message: "wandb version 0.17.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-07-04 17:14:11,129 INFO    MainThread:1986504 [wandb_init.py:init():795] starting run threads in backend
2024-07-04 17:14:16,249 INFO    MainThread:1986504 [wandb_run.py:_console_start():2374] atexit reg
2024-07-04 17:14:16,249 INFO    MainThread:1986504 [wandb_run.py:_redirect():2229] redirect: wrap_raw
2024-07-04 17:14:16,250 INFO    MainThread:1986504 [wandb_run.py:_redirect():2294] Wrapping output streams.
2024-07-04 17:14:16,250 INFO    MainThread:1986504 [wandb_run.py:_redirect():2319] Redirects installed.
2024-07-04 17:14:16,252 INFO    MainThread:1986504 [wandb_init.py:init():838] run started, returning control to user process
2024-07-04 17:20:38,959 WARNING MsgRouterThr:1986504 [router.py:message_loop():77] message_loop has been closed
